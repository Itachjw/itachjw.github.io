---
permalink: /paper_reading/
title: "阅读清单"
excerpt: "阅读清单"
author_profile: true
---

## 基础（必读）
1. 完成Python和PyTorch的基础知识学习，教程[包括代码](https://tangshusen.me/Dive-into-DL-PyTorch/#/)
2. 从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史(https://zhuanlan.zhihu.com/p/49271699)
3. 何凯明MIT第一课[Deep Learning Bootcamp](https://www.bilibili.com/video/BV1L2421T79K/?spm_id_from=333.337.search-card.all.click&vd_source=e3a52059ce83c50bdf9f1d50424534ed)
4. [2023何凯明未来科学家大会报告](https://www.bilibili.com/video/BV1QN41137qC/?spm_id_from=333.337.search-card.all.click&vd_source=e3a52059ce83c50bdf9f1d50424534ed)
5. 理解《统计学习方法》第一章中的模型、策略、算法。
6. 复旦大学邱锡鹏教授的[《神经网络与深度学习》](https://nndl.github.io/nndl-book.pdf)

##这些经典内容可能需要反复阅读，常翻出来看看，温故而知新

## 深度学习经典论文（必读）

1. [Deep residual learning for image recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)
2. [Efficient Estimation of Word Representations in Vector Space](https://openreview.net/forum?id=idpCdOWtqXd60)
3. [Focal loss for dense object detection](https://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf)
4. [Momentum Contrast for Unsupervised Visual Representation Learning](https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf)
5. [Non-local Neural Networks](https://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Non-Local_Neural_Networks_CVPR_2018_paper.pdf)
6. [Attention Is All You Need](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
7. [Learning Transferable Visual Models From Natural Language Supervision](https://proceedings.mlr.press/v139/radford21a/radford21a.pdf)
8. [ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision](https://proceedings.mlr.press/v139/kim21k/kim21k.pdf)
9. [Align before Fuse: Vision and Language Representation Learning with Momentum Distillation](https://proceedings.neurips.cc/paper/2021/file/505259756244493872b7709a8a01b536-Paper.pdf)
10. [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1163.pdf)

## 实践代码 
1. 读懂[论文](https://ojs.aaai.org/index.php/AAAI/article/view/17289)和[代码](https://github.com/thuiar/Self-MM/tree/main)，在colab上运行成功，并尝试复现该论文中的实验结果

## 推荐课程
1. Carnegie Mellon University course [11777: Multimodal Machine Learning](https://cmu-multicomp-lab.github.io/mmml-course/fall2023/)
2. Carnegie Mellon University course [11776: Multimodal Affective Computing](http://multicomp.cs.cmu.edu/resources/lti-11776-multimodal-affective-computing/)

## 常看常新
1. [找坑+填坑+编故事](https://zhuanlan.zhihu.com/p/702311751)

### 选读论文

### 多模态情感计算

1. [Misa: Modality-invariant and-specific representations for multimodal sentiment analysis](https://dl.acm.org/doi/pdf/10.1145/3394171.3413678)
2. [Learning Modality-Specific Representations with Self-Supervised Multi-Task Learning for Multimodal Sentiment Analysis](https://ojs.aaai.org/index.php/AAAI/article/view/17289)
3. [CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotations of Modality](https://aclanthology.org/2020.acl-main.343.pdf)
4. [Awesome Multimodal Sentiment Analysis](https://github.com/thuiar/AWESOME-MSA)

### 长尾学习

1. [Feature space augmentation for long-tailed data](https://arxiv.org/pdf/2008.03673)
2. [Long-tailed Recognition by Routing Diverse Distribution-Aware Experts](https://arxiv.org/pdf/2010.01809)
3. [BBN: Bilateral-branch network with cumulative learning for long-tailed visual recognition](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhou_BBN_Bilateral-Branch_Network_With_Cumulative_Learning_for_Long-Tailed_Visual_Recognition_CVPR_2020_paper.pdf)

### 持续学习

1. [iCaRL: Incremental Classifier and Representation Learning](https://openaccess.thecvf.com/content_cvpr_2017/papers/Rebuffi_iCaRL_Incremental_Classifier_CVPR_2017_paper.pdf)
1. [Gradient episodic memory for continual learning](https://proceedings.neurips.cc/paper/2017/file/f87522788a2be2d171666752f97ddebb-Paper.pdf)
1. [Large scale incremental learning](http://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_Large_Scale_Incremental_Learning_CVPR_2019_paper.pdf)

### 半监督学习

1. [FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidenc](https://proceedings.neurips.cc/paper/2020/file/06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf)
1. [Mixmatch: A holistic approach to semi-supervised learning](https://proceedings.neurips.cc/paper/2019/file/1cd138d0499a68f4bb72bee04bbec2d7-Paper.pdf)
1. [Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results](https://proceedings.neurips.cc/paper/2017/file/68053af2923e00204c3ca7c6a3150cf7-Paper.pdf)

### 噪声标签学习

1. [Co-teaching: Robust training of deep neural networks with extremely noisy labels](https://proceedings.neurips.cc/paper/2018/file/a19744e268754fb0148b017647355b7b-Paper.pdf)
1. [Meta-weight-net: Learning an explicit mapping for sample weighting](https://proceedings.neurips.cc/paper/2019/file/e58cc5ca94270acaceed13bc82dfedf7-Paper.pdf)
1. [Dividemix: Learning with noisy labels as semi-supervised learning](https://arxiv.org/pdf/2002.07394.pdf%C3%AF%C2%BC%E2%80%B0%C3%A3%E2%82%AC%E2%80%9A)



